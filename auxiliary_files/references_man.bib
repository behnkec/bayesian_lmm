@article{lee11,
  title = {How Cognitive Modeling Can Benefit from Hierarchical {{Bayesian}} Models},
  author = {Lee, Michael D.},
  date = {2011-02-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  series = {Special {{Issue}} on {{Hierarchical Bayesian Models}}},
  volume = {55},
  number = {1},
  pages = {1--7},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2010.08.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0022249610001148},
  urldate = {2024-09-24},
  abstract = {Hierarchical Bayesian modeling provides a flexible and interpretable way of extending simple models of cognitive processes. To introduce this special issue, we discuss four of the most important potential hierarchical Bayesian contributions. The first involves the development of more complete theories, including accounting for variation coming from sources like individual differences in cognition. The second involves the capability to account for observed behavior in terms of the combination of multiple different cognitive processes. The third involves using a few key psychological variables to explain behavior on a wide range of cognitive tasks. The fourth involves the conceptual unification and integration of disparate cognitive models. For all of these potential contributions, we outline an appropriate general hierarchical Bayesian modeling structure. We also highlight current models that already use the hierarchical Bayesian approach, as well as identifying research areas that could benefit from its adoption.},
  file = {/Users/clarabehnke/Zotero/storage/KYRBHT5Q/S0022249610001148.html}
}

@article{burkner18,
  title = {Advanced {{Bayesian Multilevel Modeling}} with the {{R Package}} Brms},
  author = {Bürkner, Paul-Christian},
  date = {2018},
  journaltitle = {The R Journal},
  shortjournal = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395},
  issn = {2073-4859},
  doi = {10.32614/RJ-2018-017},
  url = {https://journal.r-project.org/archive/2018/RJ-2018-017/index.html},
  urldate = {2024-04-18},
  abstract = {The brms package allows R users to easily specify a wide range of Bayesian single-level and multilevel models which are fit with the probabilistic programming language Stan behind the scenes. Several response distributions are supported, of which all parameters (e.g., location, scale, and shape) can be predicted. Non-linear relationships may be specified using non-linear predictor terms or semi-parametric approaches such as splines or Gaussian processes. Multivariate models can be fit as well. To make all of these modeling options possible in a multilevel framework, brms provides an intuitive and powerful formula syntax, which extends the well known formula syntax of lme4. The purpose of the present paper is to introduce this syntax in detail and to demonstrate its usefulness with four examples, each showing relevant aspects of the syntax.},
  langid = {english},
  file = {/Users/clarabehnke/Zotero/storage/87IPFU2S/Bürkner - 2018 - Advanced Bayesian Multilevel Modeling with the R P.pdf}
}

@article{kruschke21,
  title = {Bayesian {{Analysis Reporting Guidelines}}},
  author = {Kruschke, John K.},
  date = {2021-10},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  volume = {5},
  number = {10},
  pages = {1282--1291},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01177-7},
  url = {https://www.nature.com/articles/s41562-021-01177-7},
  urldate = {2024-08-19},
  abstract = {Previous surveys of the literature have shown that reports of statistical analyses often lack important information, causing lack of transparency and failure of reproducibility. Editors and authors agree that guidelines for reporting should be encouraged. This Review presents a set of Bayesian analysis reporting guidelines (BARG). The BARG encompass the features of previous guidelines, while including many additional details for contemporary Bayesian analyses, with explanations. An extensive example of applying the BARG is presented. The BARG should be useful to researchers, authors, reviewers, editors, educators and students. Utilization, endorsement and promotion of the BARG may improve the quality, transparency and reproducibility of Bayesian analyses.},
  langid = {english},
  keywords = {Medical research,Psychology},
  file = {/Users/clarabehnke/Zotero/storage/DRDE2PNE/Kruschke - 2021 - Bayesian Analysis Reporting Guidelines.pdf}
}

@article{eimer11a,
  title = {The {{Face-Sensitivity}} of the {{N170 Component}}},
  author = {Eimer, Martin},
  date = {2011-10-18},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {5},
  eprint = {22022313},
  eprinttype = {pmid},
  pages = {119},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2011.00119},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3196313/},
  urldate = {2024-09-25},
  pmcid = {PMC3196313},
  file = {/Users/clarabehnke/Zotero/storage/UT2K3FKR/Eimer - 2011 - The Face-Sensitivity of the N170 Component.pdf}
}

@article{brown21,
  title = {An {{Introduction}} to {{Linear Mixed-Effects Modeling}} in {{R}}},
  author = {Brown, Violet A.},
  date = {2021-01-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {1},
  pages = {2515245920960351},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245920960351},
  url = {https://doi.org/10.1177/2515245920960351},
  urldate = {2024-08-07},
  abstract = {This Tutorial serves as both an approachable theoretical introduction to mixed-effects modeling and a practical introduction to how to implement mixed-effects models in R. The intended audience is researchers who have some basic statistical knowledge, but little or no experience implementing mixed-effects models in R using their own data. In an attempt to increase the accessibility of this Tutorial, I deliberately avoid using mathematical terminology beyond what a student would learn in a standard graduate-level statistics course, but I reference articles and textbooks that provide more detail for interested readers. This Tutorial includes snippets of R code throughout; the data and R script used to build the models described in the text are available via OSF at https://osf.io/v6qag/, so readers can follow along if they wish. The goal of this practical introduction is to provide researchers with the tools they need to begin implementing mixed-effects models in their own research.},
  langid = {english},
  file = {/Users/clarabehnke/Zotero/storage/7XRPWH8Z/Brown - 2021 - An Introduction to Linear Mixed-Effects Modeling i.pdf}
}

@character(0)
@article{joe06,
  title = {Generating Random Correlation Matrices Based on Partial Correlations},
  author = {Joe, Harry},
  date = {2006-11-01},
  journaltitle = {Journal of Multivariate Analysis},
  shortjournal = {Journal of Multivariate Analysis},
  volume = {97},
  number = {10},
  pages = {2177--2189},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2005.05.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0047259X05000886},
  urldate = {2024-10-15},
  abstract = {A d-dimensional positive definite correlation matrix R=(ρij) can be parametrized in terms of the correlations ρi,i+1 for i=1,…,d-1, and the partial correlations ρij|i+1,…j-1 for j-i⩾2. These d2 parameters can independently take values in the interval (-1,1). Hence we can generate a random positive definite correlation matrix by choosing independent distributions Fij, 1⩽i},
  keywords = {Beta distribution,Determinant of correlation matrix},
  file = {/Users/clarabehnke/Zotero/storage/NAH6QPCV/S0047259X05000886.html}
}

@online{burkner24,
  title = {Estimating {{Distributional Models}} with Brms},
  author = {Bürkner, Paul-Christian},
  date = {2024-03-19},
  url = {https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html}
}

@software{standevelopmentteam24,
  title = {Stan {{Modeling Language Users Guide}} and {{Reference Manual}}},
  author = {Stan Development Team},
  date = {2024},
  url = {https://mc-stan.org},
  version = {2.35}
}

@online{betancourt18,
  title = {A {{Conceptual Introduction}} to {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, Michael},
  date = {2018-07-15},
  eprint = {1701.02434},
  eprinttype = {arXiv},
  eprintclass = {stat},
  url = {http://arxiv.org/abs/1701.02434},
  urldate = {2024-05-05},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Statistics - Methodology},
  file = {/Users/clarabehnke/Zotero/storage/YHCI2JP3/Betancourt - 2018 - A Conceptual Introduction to Hamiltonian Monte Car.pdf}
}

@article{roy20,
  title = {Convergence {{Diagnostics}} for {{Markov Chain Monte Carlo}}},
  author = {Roy, Vivekananda},
  date = {2020-03-07},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {7},
  pages = {387--412},
  publisher = {Annual Reviews},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-031219-041300},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-031219-041300},
  urldate = {2024-08-15},
  abstract = {Markov chain Monte Carlo (MCMC) is one of the most useful approaches to scientific computing because of its flexible construction, ease of use, and generality. Indeed, MCMC is indispensable for performing Bayesian analysis. Two critical questions that MCMC practitioners need to address are where to start and when to stop the simulation. Although a great amount of research has gone into establishing convergence criteria and stopping rules with sound theoretical foundation, in practice, MCMC users often decide convergence by applying empirical diagnostic tools. This review article discusses the most widely used MCMC convergence diagnostic tools. Some recently proposed stopping rules with firm theoretical footing are also presented. The convergence diagnostics and stopping rules are illustrated using three detailed examples.},
  issue = {Volume 7, 2020},
  langid = {english},
  file = {/Users/clarabehnke/Zotero/storage/22ASUW7M/Roy - 2020 - Convergence Diagnostics for Markov Chain Monte Car.pdf;/Users/clarabehnke/Zotero/storage/7674HTQN/annurev-statistics-031219-041300.html}
}

@article{klein24,
  title = {Distributional {{Regression}} for {{Data Analysis}}},
  author = {Klein, Nadja},
  date = {2024-04-22},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {11},
  pages = {321--346},
  publisher = {Annual Reviews},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-040722-053607},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040722-053607},
  urldate = {2024-06-27},
  abstract = {The flexible modeling of an entire distribution as a function of covariates, known as distributional regression, has seen growing interest over the past decades in both the statistics and machine learning literature. This review outlines selected state-of-the-art statistical approaches to distributional regression, complemented with alternatives from machine learning. Topics covered include the similarities and differences between these approaches, extensions, properties and limitations, estimation procedures, and the availability of software. In view of the increasing complexity and availability of large-scale data, this review also discusses the scalability of traditional estimation methods, current trends, and open challenges. Illustrations are provided using data on childhood malnutrition in Nigeria and Australian electricity prices.},
  issue = {Volume 11, 2024},
  langid = {english},
  file = {/Users/clarabehnke/Zotero/storage/JQXCDVXX/Klein - 2024 - Distributional Regression for Data Analysis.pdf;/Users/clarabehnke/Zotero/storage/2KGQ34UL/annurev-statistics-040722-053607.html}
}

@article{nickerson00,
  title = {Null Hypothesis Significance Testing: {{A}} Review of an Old and Continuing Controversy},
  shorttitle = {Null Hypothesis Significance Testing},
  author = {Nickerson, Raymond S.},
  date = {2000},
  journaltitle = {Psychological Methods},
  volume = {5},
  number = {2},
  pages = {241--301},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1463},
  doi = {10.1037/1082-989X.5.2.241},
  abstract = {Null hypothesis significance testing (NHST) is arguably the most widely used approach to hypothesis evaluation among behavioral and social scientists. It is also very controversial. A major concern expressed by critics is that such testing is misunderstood by many of those who use it. Several other objections to its use have also been raised. In this article the author reviews and comments on the claimed misunderstandings as well as on other criticisms of the approach, and he notes arguments that have been advanced in support of NHST. Alternatives and supplements to NHST are considered, as are several related recommendations regarding the interpretation of experimental data. The concluding opinion is that NHST is easily misunderstood and misused but that when applied with good judgment it can be an effective aid to the interpretation of experimental data. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Null Hypothesis Testing,Statistical Analysis},
  file = {/Users/clarabehnke/Zotero/storage/RQYJ9STA/2000-07827-007.html}
}

@article{wagenmakers07,
  title = {A Practical Solution to the Pervasive Problems of p Values},
  author = {Wagenmakers, Eric-Jan},
  date = {2007-10-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {14},
  number = {5},
  pages = {779--804},
  issn = {1531-5320},
  doi = {10.3758/BF03194105},
  url = {https://doi.org/10.3758/BF03194105},
  urldate = {2024-11-01},
  abstract = {In the field of psychology, the practice ofp value null-hypothesis testing is as widespread as ever. Despite this popularity, or perhaps because of it, most psychologists are not aware of the statistical peculiarities of thep value procedure. In particular,p values are based on data that were never observed, and these hypothetical data are themselves influenced by subjective intentions. Moreover,p values do not quantify statistical evidence. This article reviews thesep value problems and illustrates each problem with concrete examples. The three problems are familiar to statisticians but may be new to psychologists. A practical solution to thesep value problems is to adopt a model selection perspective and use the Bayesian information criterion (BIC) for statistical inference (Raftery, 1995). The BIC provides an approximation to a Bayesian hypothesis test, does not require the specification of priors, and can be easily calculated from SPSS output.},
  langid = {english},
  keywords = {Bayesian Information Criterion,Null Hypothesis,Posterior Probability,Prior Distribution,Statistical Inference},
  file = {/Users/clarabehnke/Zotero/storage/LV3KQH8I/Wagenmakers - 2007 - A practical solution to the pervasive problems ofp.pdf}
}

@article{epskamp19,
  title = {Reproducibility and {{Replicability}} in a {{Fast-Paced Methodological World}}},
  author = {Epskamp, Sacha},
  date = {2019-06-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {2},
  pages = {145--155},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245919847421},
  url = {https://doi.org/10.1177/2515245919847421},
  urldate = {2024-08-20},
  abstract = {Methodological developments and software implementations are progressing at an increasingly fast pace. The introduction and widespread acceptance of preprint archived reports and open-source software have made state-of-the-art statistical methods readily accessible to researchers. At the same time, researchers are increasingly concerned that their results should be reproducible (i.e., the same analysis should yield the same numeric results at a later time), which is a basic requirement for assessing the results’ replicability (i.e., whether results at a later time support the same conclusions). Although this age of fast-paced methodology greatly facilitates reproducibility and replicability, it also undermines them in ways not often realized by researchers. This article draws researchers’ attention to these threats and proposes guidelines to help minimize their impact. Reproducibility may be influenced by software development and change over time, a problem that is greatly compounded by the rising dependency between software packages. Replicability is affected by rapidly changing standards, researcher degrees of freedom, and possible bugs or errors in code, whether introduced by software developers or empirical researchers implementing an analysis. This article concludes with a list of recommendations to improve the reproducibility and replicability of results.},
  langid = {english},
  file = {/Users/clarabehnke/Zotero/storage/4YC6CIBB/Epskamp - 2019 - Reproducibility and Replicability in a Fast-Paced .pdf}
}

